{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "## Sanjay Dorairaj (Adapted from HMM tutorials by James Kunz, Professor, UC Berkeley, NLP )\n",
    "## Dated: March 17th 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Hidden Markov Models (HMMs) are a class of probabilistic graphical model that allow us to predict a sequence of unknown (hidden) variables from a set of observed variables. A simple example of an HMM is predicting the weather (hidden variable) based on the type of clothes that someone wears (observed). An HMM can be viewed as a Bayes Net unrolled through time with observations made at a sequence of time steps being used to predict the best hidden sequence or set of states.\n",
    "\n",
    "The below diagram from Wikipedia shows an HMM and its transitions. The scenario is that a room contains urns X1, X2 and X3, each of which contains a known mix of balls, each ball labeled y1, y2, y3 and y4. A sequence of four balls is randomly drawn. In this particular case, **the user observes a sequence of balls y1,y2,y3 and y4 and is attempting to discern the hidden state which is the right sequence of three urns that these four balls were pulled from. **\n",
    "\n",
    "![HMM](hmm_pic_wiki.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 1: HMM hidden and observed states **\n",
    "</center>\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/Hidden_Markov_model#/media/File:HiddenMarkovModel.svg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Hidden, Markov Model?\n",
    "\n",
    "The reason this is known as a Hidden Markov Model is because we are constructing an inference model based on the assumptions of a Markov process. The Markov process assumption is simply that the \"future is independent of the past given the present\". In other words, assuming we know our present state, we do not need any other historical information to predict the future state. \n",
    "\n",
    "To make this point clear, let us consider the scenario below where the weather, the hidden variable, can be hot, mild or cold and the observed variables are the type of clothing worn. The arrows represent transitions from a hidden state to another hidden state or from a hidden state to an observed variable. \n",
    "\n",
    "Notice that, true to the Markov assumption, each state only depends on the previous state and not on any other prior states. \n",
    "\n",
    "![HMM2](hmm_weather_clothes.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 2: HMM State Transitions **\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition behind HMMs\n",
    "\n",
    "HMMs are probabilistic models. They allow us to compute the joint probability of a set of hidden states given a set of observed states. The hidden states are also referred to as latent states. Once we know the joint probability of a sequence of hidden states, we determine the best possible sequence i.e. the sequence with the highest probability and choose that sequence as the best sequence of hidden states.\n",
    "\n",
    "The ratio of hidden states to observed states is not necessarily 1 is to 1 as is evidenced by Figure 1 above. The key idea is that one or more observations allow us to make an inference about a sequence of hidden states.\n",
    "\n",
    "In order to compute the joint probability of a sequence of hidden states, we need to assemble three types of information.\n",
    "\n",
    "Generally, the term states are used to refer to the hidden states and observations are used to refer to the observed states.\n",
    "\n",
    "1. **Transition data** - the probability of transitioning to a new state conditioned on a present state.\n",
    "2. **Emission data** - the probability of transition to an observed state conditioned on a hidden state.\n",
    "3. **Initial state information** - the initial probability of transitioning to a hidden state. This can also be looked at as the prior probability.\n",
    "\n",
    "The above information can be computed directly from our training data. For example, in the case of our weather example in Figure 2, our training data would consist of the hidden state and observations for a number of days. We could build our transition matrices of transitions, emissions and initial state probabilities directly from this training data.\n",
    "\n",
    "The example tables show a set of possible values that could be derived for the weather/clothing scenario.\n",
    "\n",
    "![HMM Tables](hmm_sample_weather_tables.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 3: HMM State Transitions - Weather Example **\n",
    "</center>\n",
    "\n",
    "Once this information is known, then the joint probability of sequence, by the conditional probability chain rule and by Markov assumption, can be shown to be proportional to be given by\n",
    "\n",
    "![HMM Basic Math](hmm_basic_math.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 4: HMM - Basic Math**\n",
    "</center>\n",
    "\n",
    "Note that as the number of observed states and hidden states gets large the compution gets more computationally intractable. If there are k possible values for each hidden sequence and we have a sequence length of n, there there are $n^k$ total possible sequences that must be all scored and ranked in order to determine a winning candidate.\n",
    "\n",
    "## Variations of the Hidden Markov Model - HMM EM\n",
    "\n",
    "Probability distributions of hidden states is not always known. In this case, we use Expectation Maximization (EM) models in order to determine hidden state distributions. A popular algorithm is the Baum-Welch algorithm (https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer on Dynamic Programming and Summation Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "As seen the above sections on HMM, the computations become intractable as the sequence length and possible values of hidden states become large. It has been found that the problem of scoring an HMM sequence can be solved efficiently using dynamic programming, which is nothing but cached recursions. \n",
    "\n",
    "Shown below is an image of the recursive computation of a fibonnaci series\n",
    "\n",
    "![Fibonnaci Tree](fib_clip_image00525.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure 5: Fibonnacci Series - Tree**\n",
    "</center>\n",
    "\n",
    "One of the things that becomes obvious when looking at this picture is that several results (fib(x) values) are reused in the computation. By caching these results, we can greatly speed up our operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fibonnacci Computation without Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result        :2178309\n",
      "Elapsed time  :2.0609 seconds\n"
     ]
    }
   ],
   "source": [
    "# non-cached recursion\n",
    "def fib(x):\n",
    "    \n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(x-1) + fib(x-2)\n",
    "    \n",
    "startTime = time.time()\n",
    "\n",
    "print(\"%-14s:%d\" % (\"Result\",fib(32)))\n",
    "print(\"%-14s:%.4f seconds\" % (\"Elapsed time\",time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fibonnacci Computation with Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result        :2178309\n",
      "Elapsed time  :0.0004 seconds\n"
     ]
    }
   ],
   "source": [
    "fib_cache = {}\n",
    "def fib(x):\n",
    "    \n",
    "    if fib_cache.get(x) != None:\n",
    "        return fib_cache[x]\n",
    "    \n",
    "    result = None\n",
    "    if x == 0:\n",
    "        result = 0\n",
    "    elif x == 1:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = fib(x-1) + fib(x-2)\n",
    "        \n",
    "    if fib_cache.get(x) == None:\n",
    "        fib_cache[x] = result\n",
    "        \n",
    "    return result\n",
    "    \n",
    "startTime = time.time()\n",
    "\n",
    "print(\"%-14s:%d\" % (\"Result\",fib(32)))\n",
    "print(\"%-14s:%.4f seconds\" % (\"Elapsed time\",time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice the significant improvement in performance when we move to dynamic programming or cached recursion. We use this same idea when trying to score HMM sequences as well using an algorithm called the Forward-Backward algorithm which we will talk about later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Summations\n",
    "\n",
    "Here we look at an idea that will be leveraged in the forward backward algorithm. This is idea that double summations of terms can be rearrangeed as a product of each of the individual summation.\n",
    "\n",
    "The example below explains this idea further. \n",
    "\n",
    "![HMM Summation](hmm_summation.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 6: HMM - Manipulation Summations**\n",
    "</center>\n",
    "\n",
    "The code below demonstrates this equivalency relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "# double summations\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [10,20,30]\n",
    "\n",
    "total = 0\n",
    "for i in x:\n",
    "    for j in y:\n",
    "        \n",
    "        total = total + i*j\n",
    "        \n",
    "print total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "# product of individual summations\n",
    "\n",
    "total = 0\n",
    "total1 = 0\n",
    "for i in x:\n",
    "    total1 = total1 + i\n",
    "    \n",
    "total2 = 0\n",
    "for j in y:\n",
    "    total2 = total2 + j\n",
    "    \n",
    "total = total1*total2\n",
    "\n",
    "print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Maxes\n",
    "\n",
    "Similar to manipulating double summations, the max of a double maxation can be viewed as the product of each of the individual maxations.\n",
    "\n",
    "![HMM Maxation](hmm_maxation.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 7: HMM - Manipulation Maxations**\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form1: [10, 20, 30, 20, 40, 60, 30, 60, 90]\n",
      "max(form1): 90\n"
     ]
    }
   ],
   "source": [
    "# double maxation\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [10,20,30]\n",
    "\n",
    "# form 1\n",
    "form1 = []\n",
    "for i in x:\n",
    "    for j in y:\n",
    "        \n",
    "        form1.append(i*j)\n",
    "        \n",
    "print \"form1:\",form1\n",
    "print \"max(form1):\",max(form1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "form2_1 [1, 2, 3]\n",
      "form2_2 [10, 20, 30]\n",
      "max(form2_1) * max(form2_2) 90\n"
     ]
    }
   ],
   "source": [
    "# product of individual maxations\n",
    "\n",
    "form2_1 = []\n",
    "form2_2 = []\n",
    "for i in x:\n",
    "    form2_1.append(i)\n",
    "for j in y:\n",
    "    form2_2.append(j)\n",
    "    \n",
    "print \"\\nform2_1\",form2_1\n",
    "print \"form2_2\",form2_2\n",
    "print \"max(form2_1) * max(form2_2)\", max(form2_1) * max(form2_2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will consider the toy example below and use the information from that example to train our simple HMM model\n",
    "\n",
    "![title](hmm_training1.png)\n",
    "\n",
    "<center>\n",
    "\n",
    "<br>\n",
    "\n",
    "** Figure - 8: HMM - Toy Example - Graph **\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State transition and emission probabilities\n",
    "\n",
    "\n",
    "![title](hmm_toy_example1_tables.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 9: HMM - Toy Example - Transition Tables**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring a known POS sequence given observed text\n",
    "\n",
    "In this example, we score a known sequence given some text\n",
    "\n",
    "Let us consider the below sequence\n",
    "\n",
    "![title](hmm_toy_example1_graph.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 10: HMM - Toy Example - Graph**\n",
    "</center>\n",
    "\n",
    "The score for this sequence can be computed as\n",
    "\n",
    "![title](hmm_toy_example1_scoring_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 11: HMM - Toy Example - Scoring Known Sequence**\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The joint probability for our unknown sequence is therefore\n",
    "\n",
    "\\begin{equation}\n",
    "P(A,B,A,Red,Green,Red) = [P(y_0=A) * P(x_0=Red/y_0=A)] * [P(y_1=B|y_0=A|) \n",
    "* P(x_1=Green/y_1=B)] *  [P(y_2=A|y_1=B) * P(x_2=Red/y_2=A)]  \n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= (1*1) * (1*0.75) * (1*1)   \n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= 0.75   \n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring a set of unknown sequences given some text\n",
    "\n",
    "Assuming that we need to determine the parts of speech tags (hidden state) given some sentence (the observed values), we will need to first score every possible sequence of hidden states and then pick the best sequence to determine the parts of speech for this sentence.\n",
    "\n",
    "We will score this using the below steps\n",
    "\n",
    "1. Generate the initial, transition and emission probability distribution from the sample data.\n",
    "2. Generate a list of all unknown sequence\n",
    "3. Score all unknown sequences and select the best sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate list of unknown sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# given states - what are the possible combinations\n",
    "# total number of combinations is (number of possible states)^(sequence length)\n",
    "\n",
    "def generate_sequence(states,sequence_length):\n",
    "    \n",
    "    all_sequences = []\n",
    "    \n",
    "    depth = sequence_length\n",
    "    \n",
    "    def gen_seq_recur(states,nodes,depth):\n",
    "\n",
    "        if depth == 0:\n",
    "            #print nodes\n",
    "            all_sequences.append(nodes)\n",
    "        else:\n",
    "            for state in states:\n",
    "                temp_nodes = list(nodes)\n",
    "                temp_nodes.append(state)\n",
    "                gen_seq_recur(states,temp_nodes,depth-1)\n",
    "    \n",
    "    gen_seq_recur(states,[],depth)\n",
    "                \n",
    "    return all_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score all possible sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_sequences(sequences,initial_probs,transition_probs,emission_probs,obs):\n",
    "    \n",
    "    best_score = -1\n",
    "    best_sequence = None\n",
    "    \n",
    "    sequence_scores = []\n",
    "\n",
    "    for seq in sequences:\n",
    "\n",
    "        total_score = 1\n",
    "        total_score_breakdown = []\n",
    "        first = True\n",
    "        for i in range(len(seq)):\n",
    "            state_score = 1\n",
    "\n",
    "            # compute transitition probability score\n",
    "            if first == True:\n",
    "                state_score *= initial_probs[seq[i]]\n",
    "\n",
    "                # reset first flag\n",
    "                first = False\n",
    "            else:  \n",
    "                state_score *= transition_probs[seq[i] + \"|\" + seq[i-1]]\n",
    "\n",
    "            # add to emission probability score\n",
    "            state_score *= emission_probs[obs[i] + \"|\" + seq[i]]\n",
    "\n",
    "            # update the total score\n",
    "            #print state_score\n",
    "            total_score_breakdown.append(state_score)\n",
    "            total_score *= state_score\n",
    "            \n",
    "        sequence_scores.append(total_score)\n",
    "        \n",
    "    return sequence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/sdorai000/.conda/envs/py27/lib/python2.7/site-packages/ipykernel/__main__.py:2: DeprecationWarning: the sets module is deprecated\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# pretty printing our  distributions\n",
    "from sets import Set\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def pretty_print_probs(distribs):\n",
    "    \n",
    "    rows = Set()\n",
    "    cols = Set()\n",
    "    for val in distribs.keys():\n",
    "        temp = val.split(\"|\")\n",
    "        rows.add(temp[0])\n",
    "        cols.add(temp[1])\n",
    "        \n",
    "    rows = list(rows)\n",
    "    cols = list(cols)\n",
    "\n",
    "    df = []\n",
    "    for i in range(len(rows)):\n",
    "        temp = []\n",
    "        for j in range(len(cols)):\n",
    "\n",
    "            temp.append(distribs[rows[i]+\"|\"+cols[j]])\n",
    "            \n",
    "        df.append(temp)\n",
    "        \n",
    "    I = pd.Index(rows, name=\"rows\")\n",
    "    C = pd.Index(cols, name=\"cols\")\n",
    "    df = pd.DataFrame(data=df,index=I, columns=C)\n",
    "    \n",
    "    print tabulate(df, headers='keys', tablefmt='psql')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the best sequence (Viterbi)\n",
    "\n",
    "Note that selecting the best scoring sequence is also known as the **Viterbi** score. The alternative approach is the **Minimum Bayes Risk** approach which selects the highest scoring position across all sequence scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let us consider the below graph \n",
    "\n",
    "![title](hmm_unknown_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 12: HMM - Toy Example - Scoring an Unknown Sequence**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Distributions\n",
      "{'A': 1.0, 'B': 0.0}\n",
      "\n",
      "Transition Probabilities\n",
      "+--------+-----+-----+\n",
      "| rows   |   A |   B |\n",
      "|--------+-----+-----|\n",
      "| A      |   0 |   1 |\n",
      "| B      |   1 |   0 |\n",
      "+--------+-----+-----+\n",
      "\n",
      "Emission Probabilities\n",
      "+--------+-----+------+\n",
      "| rows   |   A |    B |\n",
      "|--------+-----+------|\n",
      "| Green  |   0 | 0.75 |\n",
      "| Red    |   1 | 0.25 |\n",
      "+--------+-----+------+\n",
      "\n",
      "Scores\n",
      "Sequence:['A', 'A', 'A'],Score:0.0000\n",
      "Sequence:['A', 'A', 'B'],Score:0.0000\n",
      "Sequence:['A', 'B', 'A'],Score:0.7500\n",
      "Sequence:['A', 'B', 'B'],Score:0.0000\n",
      "Sequence:['B', 'A', 'A'],Score:0.0000\n",
      "Sequence:['B', 'A', 'B'],Score:0.0000\n",
      "Sequence:['B', 'B', 'A'],Score:0.0000\n",
      "Sequence:['B', 'B', 'B'],Score:0.0000\n"
     ]
    }
   ],
   "source": [
    "# We can use a dictionary to capture our state transitions\n",
    "\n",
    "# set of hidden states\n",
    "states = ['A','B']\n",
    "\n",
    "# set of observations\n",
    "obs = ['Red','Green','Red']\n",
    "\n",
    "# initial state probability distribution (our priors)\n",
    "initial_probs = {'A':1.0,'B':0.0}\n",
    "\n",
    "# transition probabilities\n",
    "transition_probs = {'A|A':0,'A|B':1,'B|A':1,'B|B':0}\n",
    "\n",
    "# emission probabilities\n",
    "emission_probs = {'Red|A':1,'Green|A':0,'Red|B':0.25,'Green|B':0.75}\n",
    "\n",
    "# length of sequence\n",
    "sequence_length = 3\n",
    "\n",
    "# Generate list of sequences\n",
    "nodes = []\n",
    "sequences = generate_sequence(states,sequence_length)\n",
    "\n",
    "# Score sequences\n",
    "sequence_scores = score_sequences(sequences,initial_probs,transition_probs,emission_probs,obs)\n",
    "\n",
    "# print results\n",
    "\n",
    "print(\"Initial Distributions\")\n",
    "print initial_probs\n",
    "\n",
    "print(\"\\nTransition Probabilities\")\n",
    "pretty_print_probs(transition_probs)\n",
    "\n",
    "print(\"\\nEmission Probabilities\")\n",
    "pretty_print_probs(emission_probs)\n",
    "\n",
    "print(\"\\nScores\")\n",
    "\n",
    "# Display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    print(\"Sequence:%10s,Score:%0.4f\" % (sequences[i],sequence_scores[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Let us consider the below graph \n",
    "\n",
    "![title](hmm_unknown_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 12: HMM - Toy Example - Scoring an Unknown Sequence**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Distributions\n",
      "{'Verb': 0.05, 'Noun': 0.9, 'Determiner': 0.05}\n",
      "\n",
      "Transition Probabilities\n",
      "+------------+--------+--------+--------------+\n",
      "| rows       |   Verb |   Noun |   Determiner |\n",
      "|------------+--------+--------+--------------|\n",
      "| Verb       |    0.1 |    0.8 |          0.1 |\n",
      "| Noun       |    0.1 |    0.1 |          0.8 |\n",
      "| Determiner |    0.8 |    0.1 |          0.1 |\n",
      "+------------+--------+--------+--------------+\n",
      "\n",
      "Emission Probabilities\n",
      "+--------+--------+--------+--------------+\n",
      "| rows   |   Verb |   Noun |   Determiner |\n",
      "|--------+--------+--------+--------------|\n",
      "| Bob    |   0.05 |   0.9  |         0.05 |\n",
      "| fruit  |   0.05 |   0.9  |         0.05 |\n",
      "| the    |   0.05 |   0.05 |         0.9  |\n",
      "| ate    |   0.9  |   0.05 |         0.05 |\n",
      "+--------+--------+--------+--------------+\n",
      "\n",
      "Scores\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun']                             Score:0.000002\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Verb']                             Score:0.000001\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Noun']                             Score:0.000015\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Verb']                             Score:0.000001\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Determiner']                       Score:0.000006\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Noun']                       Score:0.000262\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Verb']                       Score:0.000002\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Determiner']                 Score:0.000002\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Noun']                             Score:0.000262\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Verb']                             Score:0.000117\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Determiner']                       Score:0.000015\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Noun']                             Score:0.000262\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Verb']                             Score:0.000015\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Determiner']                       Score:0.000117\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Noun']                       Score:0.302331\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Verb']                       Score:0.002100\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Determiner']                 Score:0.002100\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Noun']                       Score:0.000015\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Verb']                       Score:0.000006\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Noun']                       Score:0.000002\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Noun']                 Score:0.000262\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Verb']                 Score:0.000002\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Determiner']           Score:0.000002\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Noun']                       Score:0.000001\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Noun']                       Score:0.000117\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Verb']                       Score:0.000001\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Noun']                 Score:0.000006\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Verb']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Noun']                 Score:0.000006\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Noun']                 Score:0.000117\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Verb']                 Score:0.000001\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Determiner']           Score:0.000001\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Noun']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Noun']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Noun']           Score:0.000001\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Verb']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Determiner']     Score:0.000000\n",
      "\n",
      " Best Sequence\n",
      "(['Noun', 'Verb', 'Determiner', 'Noun'], 0.30233088000000014)\n"
     ]
    }
   ],
   "source": [
    "# generate new sequences\n",
    "\n",
    "states = ['Noun','Verb','Determiner']\n",
    "sequence_length = 4\n",
    "initial_probs = {'Noun':0.9,'Verb':0.05,'Determiner':0.05}\n",
    "transition_probs = {'Noun|Noun':0.1,'Noun|Verb':0.1,'Noun|Determiner':0.8,\n",
    "                    'Verb|Noun':0.8,'Verb|Verb':0.1,'Verb|Determiner':0.1,\n",
    "                    'Determiner|Noun':0.1,'Determiner|Verb':0.8,'Determiner|Determiner':0.1}\n",
    "emission_probs = {'Bob|Noun':0.9,'ate|Noun':0.05,'the|Noun':0.05,'fruit|Noun':0.9,\\\n",
    "                  'Bob|Verb':0.05,'ate|Verb':0.9,'the|Verb':0.05,'fruit|Verb':0.05,\\\n",
    "                  'Bob|Determiner':0.05,'ate|Determiner':0.05,'the|Determiner':0.9,'fruit|Determiner':0.05}\n",
    "obs = ['Bob','ate','the','fruit']\n",
    "\n",
    "# print results\n",
    "\n",
    "print(\"Initial Distributions\")\n",
    "print initial_probs\n",
    "\n",
    "print(\"\\nTransition Probabilities\")\n",
    "pretty_print_probs(transition_probs)\n",
    "\n",
    "print(\"\\nEmission Probabilities\")\n",
    "pretty_print_probs(emission_probs)\n",
    "\n",
    "print(\"\\nScores\")\n",
    "\n",
    "# Generate list of sequences\n",
    "nodes = []\n",
    "sequences = generate_sequence(states,sequence_length)\n",
    "\n",
    "# Score sequences\n",
    "sequence_scores = score_sequences(sequences,initial_probs,transition_probs,emission_probs,obs)\n",
    "\n",
    "# Display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    print(\"Sequence:%-60s Score:%0.6f\" % (sequences[i],sequence_scores[i]))\n",
    "    \n",
    "# Display the winning score\n",
    "print(\"\\n Best Sequence\")\n",
    "print(sequences[sequence_scores.index(max(sequence_scores))],max(sequence_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Minimum Bayes Risk Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forward Backward Scores: {'Verb': 0.3075543675000003, 'Noun': 0.00029876343750000016, 'Determiner': 0.00029876343750000016}\n",
      "Best Score:0.3075543675, Best y1:['Verb']\n"
     ]
    }
   ],
   "source": [
    "# we need to first pick what it is we are looking for\n",
    "# Let's say we are looking for a Noun in the second place i.e. y1\n",
    "# We examine the set set of sequences and their scores but this \n",
    "# time we group sequences by the possible values of y1 and compute\n",
    "# the total scores within each group. The group with the highest\n",
    "# score is the forward/backward score\n",
    "\n",
    "forward_backward_index = 1 # 0-based\n",
    "\n",
    "fb_scores = {}\n",
    "\n",
    "# display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    \n",
    "    if fb_scores.get(sequences[i][forward_backward_index]) == None:\n",
    "        fb_scores[sequences[i][forward_backward_index]] = sequence_scores[i]\n",
    "    else:\n",
    "        fb_scores[sequences[i][forward_backward_index]] += sequence_scores[i]\n",
    "        \n",
    "print \"Forward Backward Scores:\", fb_scores\n",
    "\n",
    "best_fb_score = max(fb_scores.values())\n",
    "best_y1 = [key for (key,value) in fb_scores.items() if value == best_fb_score]\n",
    "print \"Best Score:%s, Best y1:%s\" % (best_fb_score,best_y1 )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
