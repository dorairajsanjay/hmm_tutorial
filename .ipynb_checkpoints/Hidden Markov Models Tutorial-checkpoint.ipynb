{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Hidden Markov Models\n",
    "\n",
    "#### Sanjay Dorairaj, UC Berkeley\n",
    "#### Adapted from HMM tutorials by James Kunz, Professor, UC Berkeley, NLP \n",
    "#### Dated: March 17th 2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "\n",
    "Hidden Markov Models (HMMs) are a class of probabilistic graphical model that allow us to predict a sequence of unknown (hidden) variables from a set of observed variables. A simple example of an HMM is predicting the weather (hidden variable) based on the type of clothes that someone wears (observed). An HMM can be viewed as a Bayes Net unrolled through time with observations made at a sequence of time steps being used to predict the best hidden sequence or set of states.\n",
    "\n",
    "The below diagram from Wikipedia shows an HMM and its transitions. The scenario is that a room contains urns X1, X2 and X3, each of which contains a known mix of balls, each ball labeled y1, y2, y3 and y4. A sequence of four balls is randomly drawn. In this particular case, **the user observes a sequence of balls y1,y2,y3 and y4 and is attempting to discern the hidden state which is the right sequence of three urns that these four balls were pulled from. **\n",
    "\n",
    "![HMM](hmm_pic_wiki.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 1: HMM hidden and observed states **\n",
    "</center>\n",
    "\n",
    "Source: https://en.wikipedia.org/wiki/Hidden_Markov_model#/media/File:HiddenMarkovModel.svg\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Hidden, Markov Model?\n",
    "\n",
    "The reason this is known as a Hidden Markov Model is because we are constructing an inference model based on the assumptions of a Markov process. The Markov process assumption is simply that the \"future is independent of the past given the present\". In other words, assuming we know our present state, we do not need any other historical information to predict the future state. \n",
    "\n",
    "To make this point clear, let us consider the scenario below where the weather, the hidden variable, can be hot, mild or cold and the observed variables are the type of clothing worn. The arrows represent transitions from a hidden state to another hidden state or from a hidden state to an observed variable. \n",
    "\n",
    "Notice that, true to the Markov assumption, each state only depends on the previous state and not on any other prior states. \n",
    "\n",
    "![HMM2](hmm_weather_clothes.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 2: HMM State Transitions **\n",
    "</center>\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intuition behind HMMs\n",
    "\n",
    "HMMs are probabilistic models. They allow us to compute the joint probability of a set of hidden states given a set of observed states. The hidden states are also referred to as latent states. Once we know the joint probability of a sequence of hidden states, we determine the best possible sequence i.e. the sequence with the highest probability and choose that sequence as the best sequence of hidden states.\n",
    "\n",
    "The ratio of hidden states to observed states is not necessarily 1 is to 1 as is evidenced by Figure 1 above. The key idea is that one or more observations allow us to make an inference about a sequence of hidden states.\n",
    "\n",
    "In order to compute the joint probability of a sequence of hidden states, we need to assemble three types of information.\n",
    "\n",
    "Generally, the term states are used to refer to the hidden states and observations are used to refer to the observed states.\n",
    "\n",
    "1. **Transition data** - the probability of transitioning to a new state conditioned on a present state.\n",
    "2. **Emission data** - the probability of transition to an observed state conditioned on a hidden state.\n",
    "3. **Initial state information** - the initial probability of transitioning to a hidden state. This can also be looked at as the prior probability.\n",
    "\n",
    "The above information can be computed directly from our training data. For example, in the case of our weather example in Figure 2, our training data would consist of the hidden state and observations for a number of days. We could build our transition matrices of transitions, emissions and initial state probabilities directly from this training data.\n",
    "\n",
    "The example tables show a set of possible values that could be derived for the weather/clothing scenario.\n",
    "\n",
    "![HMM Tables](hmm_sample_weather_tables.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 3: HMM State Transitions - Weather Example **\n",
    "</center>\n",
    "\n",
    "Once this information is known, then the joint probability of sequence, by the conditional probability chain rule and by Markov assumption, can be shown to be proportional to be given by\n",
    "\n",
    "![HMM Basic Math](hmm_basic_math.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 4: HMM - Basic Math**\n",
    "</center>\n",
    "\n",
    "Note that as the number of observed states and hidden states gets large the compution gets more computationally intractable. If there are k possible values for each hidden sequence and we have a sequence length of n, there there are $n^k$ total possible sequences that must be all scored and ranked in order to determine a winning candidate.\n",
    "\n",
    "## Variations of the Hidden Markov Model - HMM EM\n",
    "\n",
    "Probability distributions of hidden states is not always known. In this case, we use Expectation Maximization (EM) models in order to determine hidden state distributions. A popular algorithm is the Baum-Welch algorithm (https://en.wikipedia.org/wiki/Baum%E2%80%93Welch_algorithm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Primer on Dynamic Programming and Summation Rules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming\n",
    "\n",
    "As seen the above sections on HMM, the computations become intractable as the sequence length and possible values of hidden states become large. It has been found that the problem of scoring an HMM sequence can be solved efficiently using dynamic programming, which is nothing but cached recursions. \n",
    "\n",
    "Shown below is an image of the recursive computation of a fibonnaci series\n",
    "\n",
    "![Fibonnaci Tree](fib_clip_image00525.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure 5: Fibonnacci Series - Tree**\n",
    "</center>\n",
    "\n",
    "One of the things that becomes obvious when looking at this picture is that several results (fib(x) values) are reused in the computation. By caching these results, we can greatly speed up our operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fibonnacci Computation without Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result        :2178309\n",
      "Elapsed time  :2.0062 seconds\n"
     ]
    }
   ],
   "source": [
    "# non-cached recursion\n",
    "def fib(x):\n",
    "    \n",
    "    if x == 0:\n",
    "        return 0\n",
    "    elif x == 1:\n",
    "        return 1\n",
    "    else:\n",
    "        return fib(x-1) + fib(x-2)\n",
    "    \n",
    "startTime = time.time()\n",
    "\n",
    "print(\"%-14s:%d\" % (\"Result\",fib(32)))\n",
    "print(\"%-14s:%.4f seconds\" % (\"Elapsed time\",time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fibonnacci Computation with Dynamic Programming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result        :2178309\n",
      "Elapsed time  :0.0007 seconds\n"
     ]
    }
   ],
   "source": [
    "fib_cache = {}\n",
    "def fib(x):\n",
    "    \n",
    "    if fib_cache.get(x) != None:\n",
    "        return fib_cache[x]\n",
    "    \n",
    "    result = None\n",
    "    if x == 0:\n",
    "        result = 0\n",
    "    elif x == 1:\n",
    "        result = 1\n",
    "    else:\n",
    "        result = fib(x-1) + fib(x-2)\n",
    "        \n",
    "    if fib_cache.get(x) == None:\n",
    "        fib_cache[x] = result\n",
    "        \n",
    "    return result\n",
    "    \n",
    "startTime = time.time()\n",
    "\n",
    "print(\"%-14s:%d\" % (\"Result\",fib(32)))\n",
    "print(\"%-14s:%.4f seconds\" % (\"Elapsed time\",time.time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "Notice the significant improvement in performance when we move to dynamic programming or cached recursion. We use this same idea when trying to score HMM sequences as well using an algorithm called the Forward-Backward algorithm which we will talk about later"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Summations\n",
    "\n",
    "Here we look at an idea that will be leveraged in the forward backward algorithm. This is idea that double summations of terms can be rearrangeed as a product of each of the individual summation.\n",
    "\n",
    "The example below explains this idea further. \n",
    "\n",
    "![HMM Summation](hmm_summation.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure 6: HMM - Manipulation Summations**\n",
    "</center>\n",
    "\n",
    "The code below demonstrates this equivalency relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "# double summations\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [10,20,30]\n",
    "\n",
    "total = 0\n",
    "for i in x:\n",
    "    for j in y:\n",
    "        \n",
    "        total = total + i*j\n",
    "        \n",
    "print total  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "# product of individual summations\n",
    "\n",
    "total = 0\n",
    "total1 = 0\n",
    "for i in x:\n",
    "    total1 = total1 + i\n",
    "    \n",
    "total2 = 0\n",
    "for j in y:\n",
    "    total2 = total2 + j\n",
    "    \n",
    "total = total1*total2\n",
    "\n",
    "print total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manipulating Maxes\n",
    "\n",
    "Similar to manipulating double summations, the max of a double maxation can be viewed as the product of each of the individual maxations.\n",
    "\n",
    "![HMM Maxation](hmm_maxation.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 7: HMM - Manipulation Maxations**\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "form1: [10, 20, 30, 20, 40, 60, 30, 60, 90]\n",
      "max(form1): 90\n"
     ]
    }
   ],
   "source": [
    "# double maxation\n",
    "\n",
    "x = [1,2,3]\n",
    "y = [10,20,30]\n",
    "\n",
    "# form 1\n",
    "form1 = []\n",
    "for i in x:\n",
    "    for j in y:\n",
    "        \n",
    "        form1.append(i*j)\n",
    "        \n",
    "print \"form1:\",form1\n",
    "print \"max(form1):\",max(form1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "form2_1 [1, 2, 3]\n",
      "form2_2 [10, 20, 30]\n",
      "max(form2_1) * max(form2_2) 90\n"
     ]
    }
   ],
   "source": [
    "# product of individual maxations\n",
    "\n",
    "form2_1 = []\n",
    "form2_2 = []\n",
    "for i in x:\n",
    "    form2_1.append(i)\n",
    "for j in y:\n",
    "    form2_2.append(j)\n",
    "    \n",
    "print \"\\nform2_1\",form2_1\n",
    "print \"form2_2\",form2_2\n",
    "print \"max(form2_1) * max(form2_2)\", max(form2_1) * max(form2_2)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training an HMM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will consider the toy example below and use the information from that example to train our simple HMM model\n",
    "\n",
    "![title](hmm_training1.png)\n",
    "\n",
    "<center>\n",
    "\n",
    "<br>\n",
    "\n",
    "** Figure - 8: HMM - Toy Example - Graph **\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# State transition and emission probabilities\n",
    "\n",
    "\n",
    "![title](hmm_toy_example1_tables.png)\n",
    "\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 9: HMM - Toy Example - Transition Tables**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring a known POS sequence given observed text\n",
    "\n",
    "In this example, we score a known sequence given some text\n",
    "\n",
    "Let us consider the below sequence\n",
    "\n",
    "![title](hmm_toy_example1_graph.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 10: HMM - Toy Example - Graph**\n",
    "</center>\n",
    "\n",
    "The score for this sequence can be computed as\n",
    "\n",
    "![title](hmm_toy_example1_scoring_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 11: HMM - Toy Example - Scoring Known Sequence**\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "The joint probability for our unknown sequence is therefore\n",
    "\n",
    "\\begin{equation}\n",
    "P(A,B,A,Red,Green,Red) = [P(y_0=A) * P(x_0=Red/y_0=A)] * [P(y_1=B|y_0=A|) \n",
    "* P(x_1=Green/y_1=B)] *  [P(y_2=A|y_1=B) * P(x_2=Red/y_2=A)]  \n",
    "\\end{equation} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= (1*1) * (1*0.75) * (1*1)   \n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\begin{equation}\n",
    "= 0.75   \n",
    "\\end{equation} \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scoring a set of unknown sequences given some text\n",
    "\n",
    "Assuming that we need to determine the parts of speech tags (hidden state) given some sentence (the observed values), we will need to first score every possible sequence of hidden states and then pick the best sequence to determine the parts of speech for this sentence.\n",
    "\n",
    "We will score this using the below steps\n",
    "\n",
    "1. Generate the initial, transition and emission probability distribution from the sample data.\n",
    "2. Generate a list of all unknown sequence\n",
    "3. Score all unknown sequences and select the best sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate list of unknown sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# given states - what are the possible combinations\n",
    "# total number of combinations is (number of possible states)^(sequence length)\n",
    "\n",
    "def generate_sequence(states,sequence_length):\n",
    "    \n",
    "    all_sequences = []\n",
    "    nodes = []\n",
    "    \n",
    "    depth = sequence_length\n",
    "    \n",
    "    def gen_seq_recur(states,nodes,depth):\n",
    "\n",
    "        if depth == 0:\n",
    "            #print nodes\n",
    "            all_sequences.append(nodes)\n",
    "        else:\n",
    "            for state in states:\n",
    "                temp_nodes = list(nodes)\n",
    "                temp_nodes.append(state)\n",
    "                gen_seq_recur(states,temp_nodes,depth-1)\n",
    "    \n",
    "    gen_seq_recur(states,[],depth)\n",
    "                \n",
    "    return all_sequences\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score all possible sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def score_sequences(sequences,initial_probs,transition_probs,emission_probs,obs):\n",
    "    \n",
    "    best_score = -1\n",
    "    best_sequence = None\n",
    "    \n",
    "    sequence_scores = []\n",
    "\n",
    "    for seq in sequences:\n",
    "\n",
    "        total_score = 1\n",
    "        total_score_breakdown = []\n",
    "        first = True\n",
    "        for i in range(len(seq)):\n",
    "            state_score = 1\n",
    "\n",
    "            # compute transitition probability score\n",
    "            if first == True:\n",
    "                state_score *= initial_probs[seq[i]]\n",
    "\n",
    "                # reset first flag\n",
    "                first = False\n",
    "            else:  \n",
    "                state_score *= transition_probs[seq[i] + \"|\" + seq[i-1]]\n",
    "\n",
    "            # add to emission probability score\n",
    "            state_score *= emission_probs[obs[i] + \"|\" + seq[i]]\n",
    "\n",
    "            # update the total score\n",
    "            #print state_score\n",
    "            total_score_breakdown.append(state_score)\n",
    "            total_score *= state_score\n",
    "            \n",
    "        sequence_scores.append(total_score)\n",
    "        \n",
    "    return sequence_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pretty printing our  distributions\n",
    "from sets import Set\n",
    "import pandas as pd\n",
    "from tabulate import tabulate\n",
    "\n",
    "def pretty_print_probs(distribs):\n",
    "    \n",
    "    rows = Set()\n",
    "    cols = Set()\n",
    "    for val in distribs.keys():\n",
    "        temp = val.split(\"|\")\n",
    "        rows.add(temp[0])\n",
    "        cols.add(temp[1])\n",
    "        \n",
    "    rows = list(rows)\n",
    "    cols = list(cols)\n",
    "\n",
    "    df = []\n",
    "    for i in range(len(rows)):\n",
    "        temp = []\n",
    "        for j in range(len(cols)):\n",
    "\n",
    "            temp.append(distribs[rows[i]+\"|\"+cols[j]])\n",
    "            \n",
    "        df.append(temp)\n",
    "        \n",
    "    I = pd.Index(rows, name=\"rows\")\n",
    "    C = pd.Index(cols, name=\"cols\")\n",
    "    df = pd.DataFrame(data=df,index=I, columns=C)\n",
    "    \n",
    "    print tabulate(df, headers='keys', tablefmt='psql')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initializeSequences(_obs):\n",
    "    # Generate list of sequences\n",
    "    \n",
    "    seqLen = len(_obs)\n",
    "\n",
    "    seqs = generate_sequence(states,seqLen)\n",
    "\n",
    "    # Score sequences\n",
    "    seq_scores = score_sequences(seqs,initial_probs,transition_probs,emission_probs,obs)\n",
    "    \n",
    "    return (seqLen,seqs,seq_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute the best sequence (Viterbi)\n",
    "\n",
    "Note that selecting the best scoring sequence is also known as the **Viterbi** score. The alternative approach is the **Minimum Bayes Risk** approach which selects the highest scoring position across all sequence scores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 1\n",
    "\n",
    "Let us consider the below graph \n",
    "\n",
    "![title](hmm_unknown_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 12: HMM - Toy Example - Scoring an Unknown Sequence**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Distributions\n",
      "{'A': 1.0, 'B': 0.0}\n",
      "\n",
      "Transition Probabilities\n",
      "+--------+-----+-----+\n",
      "| rows   |   A |   B |\n",
      "|--------+-----+-----|\n",
      "| A      |   0 |   1 |\n",
      "| B      |   1 |   0 |\n",
      "+--------+-----+-----+\n",
      "\n",
      "Emission Probabilities\n",
      "+--------+-----+------+\n",
      "| rows   |   A |    B |\n",
      "|--------+-----+------|\n",
      "| Green  |   0 | 0.75 |\n",
      "| Red    |   1 | 0.25 |\n",
      "+--------+-----+------+\n",
      "\n",
      "Scores\n",
      "Sequence:['A', 'A', 'A'],Score:0.0000\n",
      "Sequence:['A', 'A', 'B'],Score:0.0000\n",
      "Sequence:['A', 'B', 'A'],Score:0.7500\n",
      "Sequence:['A', 'B', 'B'],Score:0.0000\n",
      "Sequence:['B', 'A', 'A'],Score:0.0000\n",
      "Sequence:['B', 'A', 'B'],Score:0.0000\n",
      "Sequence:['B', 'B', 'A'],Score:0.0000\n",
      "Sequence:['B', 'B', 'B'],Score:0.0000\n"
     ]
    }
   ],
   "source": [
    "# We can use a dictionary to capture our state transitions\n",
    "\n",
    "# set of hidden states\n",
    "states = ['A','B']\n",
    "\n",
    "# set of observations\n",
    "obs = ['Red','Green','Red']\n",
    "\n",
    "# initial state probability distribution (our priors)\n",
    "initial_probs = {'A':1.0,'B':0.0}\n",
    "\n",
    "# transition probabilities\n",
    "transition_probs = {'A|A':0,'A|B':1,'B|A':1,'B|B':0}\n",
    "\n",
    "# emission probabilities\n",
    "emission_probs = {'Red|A':1,'Green|A':0,'Red|B':0.25,'Green|B':0.75}\n",
    "\n",
    "# Generate list of sequences\n",
    "sequence_length,sequences,sequence_scores = initializeSequences(obs)\n",
    "\n",
    "# print results\n",
    "\n",
    "print(\"Initial Distributions\")\n",
    "print initial_probs\n",
    "\n",
    "print(\"\\nTransition Probabilities\")\n",
    "pretty_print_probs(transition_probs)\n",
    "\n",
    "print(\"\\nEmission Probabilities\")\n",
    "pretty_print_probs(emission_probs)\n",
    "\n",
    "print(\"\\nScores\")\n",
    "\n",
    "# Display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    print(\"Sequence:%10s,Score:%0.4f\" % (sequences[i],sequence_scores[i]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example 2\n",
    "\n",
    "Let us consider the below graph \n",
    "\n",
    "![title](hmm_unknown_sequence.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 12: HMM - Toy Example - Scoring an Unknown Sequence**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial Distributions\n",
      "{'Verb': 0.05, 'Noun': 0.9, 'Determiner': 0.05}\n",
      "\n",
      "Transition Probabilities\n",
      "+------------+--------+--------+--------------+\n",
      "| rows       |   Verb |   Noun |   Determiner |\n",
      "|------------+--------+--------+--------------|\n",
      "| Verb       |    0.1 |    0.8 |          0.1 |\n",
      "| Noun       |    0.1 |    0.1 |          0.8 |\n",
      "| Determiner |    0.8 |    0.1 |          0.1 |\n",
      "+------------+--------+--------+--------------+\n",
      "\n",
      "Emission Probabilities\n",
      "+--------+--------+--------+--------------+\n",
      "| rows   |   Verb |   Noun |   Determiner |\n",
      "|--------+--------+--------+--------------|\n",
      "| Bob    |   0.05 |   0.9  |         0.05 |\n",
      "| fruit  |   0.05 |   0.9  |         0.05 |\n",
      "| the    |   0.05 |   0.05 |         0.9  |\n",
      "| ate    |   0.9  |   0.05 |         0.05 |\n",
      "+--------+--------+--------+--------------+\n"
     ]
    }
   ],
   "source": [
    "# generate new sequences\n",
    "\n",
    "states = ['Noun','Verb','Determiner']\n",
    "initial_probs = {'Noun':0.9,'Verb':0.05,'Determiner':0.05}\n",
    "transition_probs = {'Noun|Noun':0.1,'Noun|Verb':0.1,'Noun|Determiner':0.8,\n",
    "                    'Verb|Noun':0.8,'Verb|Verb':0.1,'Verb|Determiner':0.1,\n",
    "                    'Determiner|Noun':0.1,'Determiner|Verb':0.8,'Determiner|Determiner':0.1}\n",
    "emission_probs = {'Bob|Noun':0.9,'ate|Noun':0.05,'the|Noun':0.05,'fruit|Noun':0.9,\\\n",
    "                  'Bob|Verb':0.05,'ate|Verb':0.9,'the|Verb':0.05,'fruit|Verb':0.05,\\\n",
    "                  'Bob|Determiner':0.05,'ate|Determiner':0.05,'the|Determiner':0.9,'fruit|Determiner':0.05}\n",
    "\n",
    "print(\"Initial Distributions\")\n",
    "print initial_probs\n",
    "\n",
    "print(\"\\nTransition Probabilities\")\n",
    "pretty_print_probs(transition_probs)\n",
    "\n",
    "print(\"\\nEmission Probabilities\")\n",
    "pretty_print_probs(emission_probs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Scores\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun']                             Score:0.000002\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Verb']                             Score:0.000001\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Noun']                             Score:0.000015\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Verb']                             Score:0.000001\n",
      "Sequence:['Noun', 'Noun', 'Verb', 'Determiner']                       Score:0.000006\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Noun']                       Score:0.000262\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Verb']                       Score:0.000002\n",
      "Sequence:['Noun', 'Noun', 'Determiner', 'Determiner']                 Score:0.000002\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Noun']                             Score:0.000262\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Verb']                             Score:0.000117\n",
      "Sequence:['Noun', 'Verb', 'Noun', 'Determiner']                       Score:0.000015\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Noun']                             Score:0.000262\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Verb']                             Score:0.000015\n",
      "Sequence:['Noun', 'Verb', 'Verb', 'Determiner']                       Score:0.000117\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Noun']                       Score:0.302331\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Verb']                       Score:0.002100\n",
      "Sequence:['Noun', 'Verb', 'Determiner', 'Determiner']                 Score:0.002100\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Noun']                       Score:0.000015\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Verb']                       Score:0.000006\n",
      "Sequence:['Noun', 'Determiner', 'Noun', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Noun']                       Score:0.000002\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Noun', 'Determiner', 'Verb', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Noun']                 Score:0.000262\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Verb']                 Score:0.000002\n",
      "Sequence:['Noun', 'Determiner', 'Determiner', 'Determiner']           Score:0.000002\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Verb', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Noun']                       Score:0.000001\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Noun', 'Determiner', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Noun', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Noun']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Verb']                             Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Verb', 'Determiner']                       Score:0.000000\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Noun']                       Score:0.000117\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Verb']                       Score:0.000001\n",
      "Sequence:['Verb', 'Verb', 'Determiner', 'Determiner']                 Score:0.000001\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Noun']                 Score:0.000006\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Verb']                 Score:0.000000\n",
      "Sequence:['Verb', 'Determiner', 'Determiner', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Noun']                 Score:0.000006\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Noun', 'Determiner', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Noun', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Noun']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Verb']                       Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Verb', 'Determiner']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Noun']                 Score:0.000117\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Verb']                 Score:0.000001\n",
      "Sequence:['Determiner', 'Verb', 'Determiner', 'Determiner']           Score:0.000001\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Noun']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Noun', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Noun']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Verb']                 Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Verb', 'Determiner']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Noun']           Score:0.000001\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Verb']           Score:0.000000\n",
      "Sequence:['Determiner', 'Determiner', 'Determiner', 'Determiner']     Score:0.000000\n",
      "\n",
      " Best Sequence\n",
      "(['Noun', 'Verb', 'Determiner', 'Noun'], 0.30233088000000014)\n"
     ]
    }
   ],
   "source": [
    "obs = ['Bob','ate','the','fruit']\n",
    "\n",
    "# print results\n",
    "print(\"\\nScores\")\n",
    "\n",
    "# Generate list of sequences\n",
    "sequence_length,sequences,sequence_scores = initializeSequences(obs)\n",
    "\n",
    "# Display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    print(\"Sequence:%-60s Score:%0.6f\" % (sequences[i],sequence_scores[i]))\n",
    "    \n",
    "# Display the winning score\n",
    "print(\"\\n Best Sequence\")\n",
    "print(sequences[sequence_scores.index(max(sequence_scores))],max(sequence_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Computing the Minimum Bayes Risk (MBR) Score\n",
    "\n",
    "Here, we try to find out the best possible value for a particular y location location where y represents our hidden states starting from y=0,1...n-1, where n is the sequence length\n",
    "\n",
    "For example, if we need to first pick the position we are interested in, let's say we are in the second position of the hidden sequence i.e. y1. We examine the set set of sequences and their scores but this time we group sequences by  possible values of y1 and compute the total scores within each group. The group with the highest score is the forward/backward score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum Bayes Risk Scores for :\n",
      "Verb                 0.00001816\n",
      "Noun                 0.00000108\n",
      "Determiner           0.00008688\n",
      "\n",
      "Best Score:0.00008688, \n",
      "State Index:4 \n",
      "Best y state:['Determiner']\n"
     ]
    }
   ],
   "source": [
    "# initialize the observations\n",
    "obs = ['Bob','ate','the','fruit']\n",
    "obs = ['Bob','ate','the','fruit','the','fruit','Bob','ate','ate','the','fruit']\n",
    "\n",
    "## recompute sequences and sequence scores\n",
    "sequence_length,sequences,sequence_scores = initializeSequences(obs)\n",
    "\n",
    "## compute MBR for a particular position\n",
    "mbr_index = 4 # MBR 0-based\n",
    "\n",
    "fb_scores = {}\n",
    "\n",
    "# display sequence scores\n",
    "for i in range(len(sequences)):\n",
    "    \n",
    "    if fb_scores.get(sequences[i][mbr_index]) == None:\n",
    "        fb_scores[sequences[i][mbr_index]] = sequence_scores[i]\n",
    "    else:\n",
    "        fb_scores[sequences[i][mbr_index]] += sequence_scores[i]\n",
    "        \n",
    "print \"Minimum Bayes Risk Scores for :\"\n",
    "for key in fb_scores:\n",
    "    print(\"%-20s %0.8f\" % (key,fb_scores[key]))\n",
    "    \n",
    "best_fb_score = max(fb_scores.values())\n",
    "best_y = [key for (key,value) in fb_scores.items() if value == best_fb_score]\n",
    "print \"\\nBest Score:%0.8f, \\nState Index:%d \\nBest y state:%s\" % (best_fb_score,mbr_index,best_y )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Optimizing the efficiency of HMM computations using Dynamic Programming\n",
    "\n",
    "Since predicting the optimal sequence using HMM can become computational tedious as the number of the sequence length increases, we resort to dynamic programming (cached recursion) in order to improve its performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examining computation complexity as the sequence length increases\n",
    "\n",
    "In this section, we will increase our sequence length to a much longer sentence and examine the impact on computation time. The same performance issues will also be encountered if the number of states is large, although in this case, we will only tweak the sequence length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Verb'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Determiner'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Verb', 'Noun'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Verb', 'Verb'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Verb', 'Determiner'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Determiner', 'Noun'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Determiner', 'Verb'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Determiner', 'Determiner'] Score:0.000000\n",
      "Sequence:['Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Noun', 'Verb', 'Noun', 'Noun'] Score:0.000000\n",
      "\n",
      " Best Sequence\n",
      "(['Noun', 'Verb', 'Determiner', 'Noun', 'Determiner', 'Noun', 'Noun', 'Verb', 'Verb', 'Determiner', 'Noun'], 5.92297667290203e-05)\n",
      "\n",
      " Sequence length:   11, State count:     3, Time taken:2.7134 seconds\n"
     ]
    }
   ],
   "source": [
    "# initialize a new sequence of observations\n",
    "obs = ['Bob','ate','the','fruit','the','fruit','Bob','ate','ate','the','fruit']\n",
    "\n",
    "# print results\n",
    "\n",
    "import time\n",
    "startTime = time.time()\n",
    "\n",
    "## recompute sequences and sequence scores\n",
    "sequence_length,sequences,sequence_scores = initializeSequences(obs)\n",
    "\n",
    "# Display partial list of sequence scores\n",
    "rangeLen = 0\n",
    "if len(sequences) > 10:\n",
    "    rangeLen = 10\n",
    "else:\n",
    "    rangeLen = len(sequences)\n",
    "    \n",
    "for i in range(rangeLen):\n",
    "    print(\"Sequence:%-60s Score:%0.6f\" % (sequences[i],sequence_scores[i]))\n",
    "    \n",
    "# Display the winning score\n",
    "print(\"\\n Best Sequence\")\n",
    "print(sequences[sequence_scores.index(max(sequence_scores))],max(sequence_scores))\n",
    "\n",
    "# print time\n",
    "print(\"\\n Sequence length:%5d, State count: %5d, Time taken:%0.4f seconds\" %\\\n",
    "      (sequence_length,len(initial_probs),time.time()-startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the time taken get very large even for small increases in sequence length and for a very a small state count. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Programming Intuition for HMMs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intuition behind the Dynamic Programming algorithm for computing MBR scores\n",
    "\n",
    "Dynamic programming is implemented using cached recursion. Formulating a problem recursively and caching intermediate values allows for exponential improvements in performance compared to other methods of computation.\n",
    "\n",
    "The MBR solution can be computed using dynamic programming. MBR allows us to compute the sum over all sequences conditioned on keeping one of the hidden states at a particular position fixed. This in turn allows us to determine the best score for a given state at a given position. We do this by computing the best score for every state at that position and pick the state that has the highest score.\n",
    "\n",
    "Consider the example of a sequence of four words - \"Bob ate the fruit\". Let us assume that we would like to compute the MBR score conditioned on the hidden state at position 1 (y1) being a Noun (N).\n",
    "\n",
    "This computation can be mathematically shown to be equivalent to\n",
    "\n",
    "![title](hmm_dyn_mbr_math.png)\n",
    "<center>\n",
    "<br>\n",
    "** Figure - 13: HMM - Dynamic Programming - Finding the MBR Score**\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We break up the computation into two parts. In the first part, alpha, we compute the sum of all possible ways that the sequence can end up as a Noun in position 1 and in the second part, beta, we compute the sum of all possible ways taht the sequence can start as a Noun."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward/Backward Algorithm for computing the MBR scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "alpha_cache = {}\n",
    "\n",
    "def alpha(pos,state,textList,cachedRecursion = True):\n",
    "    \n",
    "    if cachedRecursion == True:\n",
    "        \n",
    "        # if cache is enabled, try to read from cache\n",
    "        if alpha_cache.get((pos,state)) != None:\n",
    "            return alpha_cache[(pos,state)]\n",
    "        \n",
    "    if pos == 0:\n",
    "        return initial_probs[state] * emission_probs[textList[pos] + \"|\" + state]\n",
    "    else:\n",
    "        total = 0\n",
    "        for state_val in states:\n",
    "            total += alpha(pos-1,state_val,textList,cachedRecursion) \\\n",
    "            * transition_probs[state+\"|\"+state_val] * emission_probs[textList[pos]+\"|\"+state]\n",
    "        \n",
    "        # if cache is enabled, then cache\n",
    "        if cachedRecursion == True:\n",
    "            if alpha_cache.get((pos,state)) == None:\n",
    "                alpha_cache[(pos,state)] = total\n",
    "        \n",
    "        return total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "beta_cache = {}\n",
    "\n",
    "def beta(pos,state,textList,currIndex=0,currState=None,cachedRecursion = True):\n",
    "    \n",
    "    if cachedRecursion == True:\n",
    "        \n",
    "        # if cache is enabled, try to read from cache\n",
    "        if beta_cache.get((currIndex,currState)) != None:\n",
    "            return beta_cache[(currIndex,currState)]\n",
    "        \n",
    "    if currIndex == 0:\n",
    "        currIndex = len(textList)\n",
    "        \n",
    "        if pos == currIndex - 1:\n",
    "            return 1\n",
    "        \n",
    "        total = 0\n",
    "        for state_val in states:\n",
    "            tempSum = beta(pos,state,textList,currIndex-1,state_val,cachedRecursion) \n",
    "            \n",
    "            total += tempSum\n",
    "        \n",
    "        # if cache is enabled, then cache\n",
    "        if cachedRecursion == True:\n",
    "            if beta_cache.get((currIndex,currState)) == None:\n",
    "                beta_cache[(currIndex,currState)] = total\n",
    "                \n",
    "        return total\n",
    "    \n",
    "    elif currIndex == pos+1:\n",
    "\n",
    "        return transition_probs[currState+\"|\"+state] * emission_probs[textList[currIndex]+\"|\"+currState]\n",
    "  \n",
    "    else:\n",
    "        total = 0\n",
    "        for state_val in states:\n",
    "            \n",
    "            inStateProb = transition_probs[currState+\"|\"+state_val] * emission_probs[textList[currIndex]+\"|\"+currState]\n",
    "            tempSum = inStateProb *beta(pos,state,textList,currIndex-1,state_val,cachedRecursion) \n",
    "\n",
    "            total += tempSum\n",
    "            \n",
    "        # if cache is enabled, then cache\n",
    "        if cachedRecursion == True:\n",
    "            if beta_cache.get((currIndex,currState)) == None:\n",
    "                beta_cache[(currIndex,currState)] = total\n",
    "                \n",
    "        return total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dynamic Programming Performance Improvements\n",
    "\n",
    "We will now test out the dynamic programming algorithm with and without caching enabled to look at performance improvements.\n",
    "\n",
    "For our dataset, we will use a much longer sequence since we have a much more efficient algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set observations\n",
    "obs = ['Bob','ate','the','fruit','the','fruit','Bob','ate',\\\n",
    "       'ate','the','fruit','Bob','ate','the','fruit','the','fruit','Bob']\n",
    "\n",
    "position = 4\n",
    "part_of_speech = \"Determiner\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward/Backward algorithm for computing MBR score without caching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBR Score for Position:4 and POS:Determiner is 0.00000004\n",
      "\n",
      " Time taken:3.7872 seconds\n"
     ]
    }
   ],
   "source": [
    "# measure time taken without caching (dynamic programming)\n",
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "# variables for saving alpha and beta values\n",
    "alpha_cache = {}\n",
    "beta_cache = {}\n",
    "\n",
    "# get alpha\n",
    "alpha_res = alpha(position,part_of_speech,obs,cachedRecursion=False)  \n",
    "\n",
    "# get beta\n",
    "beta_res = beta(position,part_of_speech,obs,cachedRecursion=False)\n",
    "\n",
    "mbr_score = alpha_res * beta_res\n",
    "\n",
    "print(\"MBR Score for Position:%d and POS:%s is %0.8f\" % (position,part_of_speech,mbr_score))\n",
    "# print time\n",
    "print(\"\\n Time taken:%0.4f seconds\" % (time.time()-startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward/Backward algorithm for computing MBR score **with caching**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MBR Score for Position:4 and POS:Determiner is 0.00000004\n",
      "\n",
      " Time taken:0.0010 seconds\n"
     ]
    }
   ],
   "source": [
    "# measure time taken with caching (dynamic programming)\n",
    "import time\n",
    "\n",
    "startTime = time.time()\n",
    "\n",
    "# variables for saving alpha and beta values\n",
    "alpha_cache = {}\n",
    "beta_cache = {}\n",
    "\n",
    "# get alpha\n",
    "alpha_res = alpha(position,part_of_speech,obs,cachedRecursion=True)  \n",
    "\n",
    "# get beta\n",
    "beta_res = beta(position,part_of_speech,obs,cachedRecursion=True)\n",
    "\n",
    "mbr_score = alpha_res * beta_res\n",
    "\n",
    "print(\"MBR Score for Position:%d and POS:%s is %0.8f\" % (position,part_of_speech,mbr_score))\n",
    "# print time\n",
    "print(\"\\n Time taken:%0.4f seconds\" % (time.time()-startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Notice the significant improvements in time when we use the version with cached recursion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
